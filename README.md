# NLP-笔记

机器学习中几个概念解释：

1.错误率
是指模型预测错误的比例，计算方法是：错误率= 错误的预测数/总的预测数
​
2. 精度 (Accuracy)
精度是指模型预测正确的比例
精度=正确的预测数/总的预测数

3.精确率
精确度衡量的是模型预测为正类时，实际为正类的比例。
精确度=true positive /true positive +false positive

4.召回率 (Recall)
召回率衡量的是所有实际为正类的样本中，模型正确预测为正类的比例
召回率=true positive /true positive +false negative 


5.F1 值 (F1 Score)
F1 值是精确度和召回率的调和平均数，它在需要平衡精度和召回率时特别有用
F1值  = 1/(1/精确度+1/召回率) = 2 × 精确度×召回率/（精确度+召回率）

6.AUC (Area Under Curve)
AUC 是 ROC 曲线下的面积，通常用来衡量分类器的整体表现。AUC 值的范围是 [0, 1]，越接近 1，说明模型的  分类性能   越好。AUC 是通过 ROC 曲线来计算的，它是一个比较全面的评价指标，尤其在类别不平衡的情况下非常有用。



7. ROC (Receiver Operating Characteristic Curve)
ROC 曲线是一个二维图，展示了不同阈值下，分类器的 召回率（真正率）和 假阳性率（假正率）之间的关系。ROC 曲线通过改变分类决策的阈值来查看模型的性能。

真正率 (True Positive Rate, TPR): 即召回率，表示实际为正类的样本中被正确预测为正类的比例。

假阳性率 (False Positive Rate, FPR): 表示实际为负类的样本中被错误预测为正类的比例。
通过画出 ROC 曲线，可以直观地看到模型在各种阈值下的表现

总结
错误率：错误预测的比例。

精度：正确预测的比例。

精确度：预测为正类时，实际为正类的比例。

召回率：实际为正类时，正确预测为正类的比例。

F1 值：精确度和召回率的调和平均。

AUC：ROC 曲线下的面积，表示模型整体性能。

ROC 曲线：展示不同阈值下真正率和假阳性率的关系。
